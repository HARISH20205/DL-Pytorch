{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 28 00:43:16 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P0             14W /   80W |     580MiB /   8188MiB |      8%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1535      G   /usr/lib/xorg/Xorg                            212MiB |\n",
      "|    0   N/A  N/A      1925      G   /usr/bin/gnome-shell                           76MiB |\n",
      "|    0   N/A  N/A      3647      G   /opt/brave.com/brave/brave                      2MiB |\n",
      "|    0   N/A  N/A      3695      G   ...dce53a9c8f623dd28fff2540a8d57a08bc3         54MiB |\n",
      "|    0   N/A  N/A     63797      G   ...erProcess --variations-seed-version        108MiB |\n",
      "|    0   N/A  N/A    258563      G   /usr/bin/vlc                                  108MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.6.0+cu124'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7), 0, torch.Tensor, int)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar\n",
    "a = torch.tensor(7)\n",
    "\n",
    "a,a.ndim,type(a),type(a.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " tensor([[[1, 2],\n",
       "          [3, 4]]]),\n",
       " torch.Tensor,\n",
       " 1,\n",
       " torch.Tensor,\n",
       " torch.Size([2, 2]),\n",
       " 2,\n",
       " torch.Tensor,\n",
       " 3,\n",
       " torch.Size([1, 2, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector\n",
    "\n",
    "c = torch.tensor([1,2,3])\n",
    "M2 = torch.tensor( [[1,2],[3,4]])\n",
    "M3 = torch.tensor([[[1,2],\n",
    "                    [3,4]]])\n",
    "\n",
    "c,M2,M3,type(c),c.ndim,type(M2),M2.shape,M2.ndim,type(M3),M3.ndim,M3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0978, 0.6472, 0.6874],\n",
       "         [0.0379, 0.7508, 0.6820],\n",
       "         [0.9251, 0.3261, 0.0281]]),\n",
       " tensor([[[0., 0.],\n",
       "          [0., 0.]]]),\n",
       " tensor([[[1., 1., 1.],\n",
       "          [1., 1., 1.]]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1 = torch.rand(3,3)\n",
    "M2 = torch.zeros(1,2,2)\n",
    "M3 = torch.ones(1,2,3)\n",
    "M1,M2,M3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0978, 0.6472, 0.6874],\n",
       "        [0.0000, 0.7508, 0.6820],\n",
       "        [0.0000, 0.3261, 0.0281]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1[1::,0]= 0\n",
    "M1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = torch.arange(1,11)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2 = torch.arange(start=0, end=10,dtype=torch.int)\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2560, 0.2958, 0.6848, 0.8137, 0.4114, 0.5171, 0.1718, 0.5385, 0.0185,\n",
       "         0.9724], dtype=torch.float64),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R1 = torch.tensor([torch.rand(1) for x in range(10)],dtype=torch.double)\n",
    "ZR1 = torch.zeros_like(R1)\n",
    "R1,ZR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harish K B\\AppData\\Local\\Temp\\ipykernel_23364\\2046787710.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  T1 = torch.tensor(torch.arange(10),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1 = torch.tensor(torch.arange(10),\n",
    "                  requires_grad=False,\n",
    "                  dtype=torch.double,\n",
    "                  device='cpu')\n",
    "T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.float32, torch.int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f32 =torch.arange(start=100,end=111,dtype=torch.float32)\n",
    "f16 =torch.arange(start=1000,end=1011,dtype=torch.int64)\n",
    "type(f32),type(f16),f32.dtype,f16.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i64 = f32.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.float32, torch.int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f32),type(f16),f32.dtype,f16.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[0.6033, 0.4480, 0.5502, 0.2143],\n",
       "         [0.1198, 0.5370, 0.7507, 0.0363],\n",
       "         [0.6728, 0.9272, 0.0539, 0.1182],\n",
       "         [0.2703, 0.1317, 0.8682, 0.5924]]),\n",
       " tensor([[1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 1.]]),\n",
       " tensor([10, 15, 20, 25, 30, 35, 40, 45]),\n",
       " tensor([[0.3250, 0.8955, 0.1694],\n",
       "         [0.9157, 0.8865, 0.4794]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor Creation\n",
    "# Create a 2x3 tensor filled with ones.\n",
    "\n",
    "one = torch.ones(size=(2,3))\n",
    "\n",
    "\n",
    "# Create a tensor of shape (4, 4) with random values between 0 and 1.\n",
    "\n",
    "two = torch.rand(size=(4,4))\n",
    "\n",
    "# Generate a 3x3 identity matrix.\n",
    "\n",
    "three = torch.eye(n=5)\n",
    "\n",
    "# Create a tensor of integers from 10 to 50 with a step of 5.\n",
    "\n",
    "four = torch.arange(10,50,5)\n",
    "\n",
    "# Create a tensor of shape (2, 3) and then convert it to a float tensor.\n",
    "\n",
    "five = torch.rand(size=(2,3)); five = five.to(torch.float32)\n",
    "\n",
    "\n",
    "one,two,three,four,five,five.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7383, 0.0737, 0.5742, 0.2597],\n",
      "        [0.7981, 0.1443, 0.0092, 0.5502],\n",
      "        [0.3813, 0.1551, 0.9342, 0.6405],\n",
      "        [0.0421, 0.7905, 0.2509, 0.1503]])\n",
      "tensor([[0.1443, 0.0092],\n",
      "        [0.1551, 0.9342]])\n",
      "tensor([[0.0549, 0.7849, 0.1161, 0.5049],\n",
      "        [0.8501, 0.6585, 0.5292, 0.3978]])\n"
     ]
    }
   ],
   "source": [
    "# Basic Manipulations\n",
    "# Reshape a tensor of shape (4, 2) into (2, 4).\n",
    "\n",
    "one = torch.rand((4,2))\n",
    "# print(one.shape)\n",
    "\n",
    "one = one.reshape((2,4))\n",
    "# print(one.shape)\n",
    "\n",
    "\n",
    "# Concatenate two tensors of shape (2, 3) along the second dimension.\n",
    "\n",
    "\n",
    "two1 = torch.rand((4,2))\n",
    "two2 = torch.rand((4,2))\n",
    "\n",
    "two = torch.cat((two1,two2),dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# Stack three tensors of shape (2, 2) along a new dimension.\n",
    "\n",
    "three1 = torch.rand((2,2))\n",
    "three2 = torch.rand((2,2))\n",
    "three3 = torch.rand((2,2))\n",
    "\n",
    "three = torch.stack((three1,three2,three3),dim=0)\n",
    "\n",
    "\n",
    "# Slice a 4x4 tensor to extract a 2x2 sub-tensor from the center.\n",
    "\n",
    "four1 = torch.rand((4,4))\n",
    "\n",
    "print(four1)\n",
    "four = four1[1:3,1:3]\n",
    "print(four)\n",
    "# Create a tensor and compute its transpose.\n",
    "\n",
    "five = torch.rand((4,2))\n",
    "print(five.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5179, 0.0833, 0.8855],\n",
      "        [0.7494, 0.0493, 0.9736],\n",
      "        [0.6921, 0.6094, 0.4027]])\n",
      "tensor([[0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.]]) tensor([[False,  True,  True],\n",
      "        [ True, False,  True],\n",
      "        [ True,  True, False]])\n"
     ]
    }
   ],
   "source": [
    "# Advanced Manipulations\n",
    "# Create a tensor of shape (3, 3) and set the diagonal elements to 1 and all other elements to 0.\n",
    "\n",
    "one1 = torch.rand((3,3))\n",
    "\n",
    "print(one1)\n",
    "mask = ~torch.eye(3,dtype=torch.bool)\n",
    "\n",
    "one1[mask]=1\n",
    "one1.fill_diagonal_(0)\n",
    "\n",
    "print(one1,~torch.eye(3,dtype=torch.bool))\n",
    "\n",
    "# Generate a tensor of shape (3, 3) and normalize its values to the range [0, 1].\n",
    "\n",
    "# Perform element-wise multiplication of two tensors of shape (3, 3).\n",
    "\n",
    "# Replace all values in a tensor greater than 0.5 with the value 1.\n",
    "\n",
    "# Compute the dot product of two 1D tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
